{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "10FyJRp37IGJ"
   },
   "source": [
    " **DATASET ANALYSIS AND PREPROCESSING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "45glW4WrXYyV",
    "outputId": "07e9d441-29d3-43c0-9f65-b2bfae25f78b"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4ahA1GA2g2MY"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PsFVyywHg3UT",
    "outputId": "1a719a73-0ffb-41dc-aa2c-efda437329a3"
   },
   "outputs": [],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ER_h-gG_g4QM"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/content/drive/MyDrive/mtsamples.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ilgay4NZg7Ya",
    "outputId": "94644e1b-8a8f-42e4-955b-dde2d25a4691"
   },
   "outputs": [],
   "source": [
    "print(\"Initial Dataset Shape:\", df.shape)\n",
    "print(df.head())\n",
    "print(df.info())\n",
    "print(\"Unique Medical Specialties:\", df['medical_specialty'].nunique())\n",
    "print(\"Specialty Distribution:\\n\", df['medical_specialty'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ykz8k1rs7YaK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iUYgpU-77ViF"
   },
   "source": [
    "Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RZAzCeRhg85T",
    "outputId": "874b4e6e-3523-4062-d1e0-e850b79bd519"
   },
   "outputs": [],
   "source": [
    "print(\"\\nMissing Values:\\n\", df.isnull().sum())\n",
    "df = df.dropna(subset=['transcription'])\n",
    "df['keywords'].fillna('', inplace=True)\n",
    "df['description'].fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EteB2ddShRAG",
    "outputId": "5adf0e0d-a84f-4e25-b67e-29c01efc7f8f"
   },
   "outputs": [],
   "source": [
    "print(\"\\nDuplicates:\", df.duplicated().sum())\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AvD8MH4l7ao1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VcSKrZNK7P2h"
   },
   "source": [
    "Text Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZMICVpIqhmKF"
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    tokens = word_tokenize(text)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    cleaned_text = ' '.join(tokens)\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xOwa__XKhtC_"
   },
   "outputs": [],
   "source": [
    "df['cleaned_transcription'] = df['transcription'].apply(clean_text)\n",
    "df['cleaned_keywords'] = df['keywords'].apply(clean_text)\n",
    "df['cleaned_description'] = df['description'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VZonXuCoiD4r",
    "outputId": "107be907-10d4-4c03-9872-fde4876cbccb"
   },
   "outputs": [],
   "source": [
    "print(\"\\nSample Cleaned Transcription:\\n\", df['cleaned_transcription'].iloc[0])\n",
    "df['features'] = df['cleaned_transcription'] + ' ' + df['cleaned_keywords']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4aUUwUVI7crp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rfXxq-A17c9U"
   },
   "source": [
    "Splitting data into train, test and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JCbix6LjiJyJ",
    "outputId": "2dfd4735-90c3-4127-d470-e3a6af0d568a"
   },
   "outputs": [],
   "source": [
    "X = df['features']\n",
    "y = df['medical_specialty']\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "print(\"\\nTrain Shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Validation Shape:\", X_val.shape, y_val.shape)\n",
    "print(\"Train Specialty Distribution:\\n\", y_train.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LFKaJIdwiRJY"
   },
   "outputs": [],
   "source": [
    "df.to_csv('processed_mtsamples.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DiCRG7J_iSsA"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ds-ewenw7jQ8"
   },
   "source": [
    "**EDA ON PREPROCESSED DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wzff59Jbjf-j"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 615
    },
    "id": "-uhguA-WjkFb",
    "outputId": "ed9a73ef-e324-408d-bb47-16bcd6ec5db2"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "sns.countplot(y=y_train, order=y_train.value_counts().index)\n",
    "plt.title('Training Data Class Distribution')\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('Medical Specialty')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "9LNfrg_Zjlw7",
    "outputId": "4a4370b2-10e3-4839-a7e0-0dfb7c21addf"
   },
   "outputs": [],
   "source": [
    "train_lengths = X_train.apply(lambda x: len(x.split()))\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(train_lengths, bins=50, kde=True)\n",
    "plt.title('Distribution of Transcription Lengths in Train Data')\n",
    "plt.xlabel('Number of Words')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 444
    },
    "id": "1b6bCVpujm3M",
    "outputId": "6d70c9a1-c091-4e31-be8d-5652e5be9f5c"
   },
   "outputs": [],
   "source": [
    "all_text = ' '.join(X_train)\n",
    "wordcloud = WordCloud(width=800, height=400, background_color='white').generate(all_text)\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title('Word Cloud of training transcriptions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ObtRBYg7joVd",
    "outputId": "bb41f241-87a7-44f4-de70-89e43b366216"
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "word_counts = vectorizer.fit_transform(X_train)\n",
    "top_words = pd.DataFrame(word_counts.sum(axis=0), columns=vectorizer.get_feature_names_out()).T.sort_values(0, ascending=False).head(20)\n",
    "print(\"Top 20 words in train data:\\n\", top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wow6U-21jtRw"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SeOm2YqU7m2d"
   },
   "source": [
    "**TRAINING BASELINE MODEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kAEieXn6jtnp"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sO-htb2Vjwvt"
   },
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(max_features=5000, ngram_range=(1,2))\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_val_tfidf = tfidf.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 152
    },
    "id": "W0kXmQ5Njx1f",
    "outputId": "37a60490-fa9b-49cf-e594-5e32b024c81f"
   },
   "outputs": [],
   "source": [
    "clf = LogisticRegression(max_iter=1000, class_weight='balanced', multi_class='multinomial', solver='lbfgs')\n",
    "clf.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JpuEpWzoj1ru"
   },
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_val_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "efS_Gb1bj2vu",
    "outputId": "9ae86688-a92f-4044-9a95-a3eaffe45ddb"
   },
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "f1 = f1_score(y_val, y_pred, average='macro')\n",
    "print(f\"Baseline Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Baseline Macro F1: {f1:.4f}\")\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 872
    },
    "id": "HykR6Illj4Eb",
    "outputId": "a3614317-af7a-499a-b0bb-caacfaec9bab"
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_val, y_pred)\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(cm, annot=False, cmap='Blues')\n",
    "plt.title('Baseline Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eb2wkhQ4j5Ns",
    "outputId": "e10d03a6-0a25-4d97-f4d9-2304cb3b9829"
   },
   "outputs": [],
   "source": [
    "errors = pd.DataFrame({'Text': X_val[y_val != y_pred], 'True': y_val[y_val != y_pred], 'Pred': y_pred[y_val != y_pred]})\n",
    "print(\"Sample Errors:\\n\", errors.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9YKtmSkYkfrl"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FYt1n1Wx8XPC"
   },
   "source": [
    "**FINE-TUNING BIOBERT MODEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VVxBfYoWkf7G"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AphLqHg8k055"
   },
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y_train_enc = le.fit_transform(y_train)\n",
    "y_val_enc = le.transform(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uwGMWhJFk9SA"
   },
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame({'text': X_train, 'label': y_train_enc})\n",
    "val_df = pd.DataFrame({'text': X_val, 'label': y_val_enc})\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "val_dataset = Dataset.from_pandas(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 205,
     "referenced_widgets": [
      "a7a3a8db5aee4a6c997f08dc698f4e8c",
      "3a842d8abccd4a0da167a499925450b3",
      "5c4ade354ac24a9c8fa49c5952f51cfc",
      "fb13cb4f3d334a1db58024cd9b4513cc",
      "f0e092534d6d46b0aa22e239d7bdd109",
      "47a661e528114af28a41cc13372653fb",
      "2ce8c0d3e02841dfad082286863d6e82",
      "0d69595442234b69badea7455423c76f",
      "d9e2b4f0265b48fba719042389a722d5",
      "77821f6566ec4b9cab669680b420c2fe",
      "c1782c38249e46bfbb4c4ad7b99937c6",
      "52d843d366034c8d937cd783ab19a1c0",
      "01a8c82714c445229a2bac935f6b31c3",
      "a11d0061db7440b084d322ffadeab958",
      "350425aa324045db88f6ee8eb17057cb",
      "e383be0b8d7d4e89b1d9886be451fdeb",
      "d9adec2bbb1e43a1b37a8d2d7ea00a29",
      "585aca7def194399a4406691ea0fd03f",
      "02e8a855832440efa5e206a9660e7b46",
      "59f27f2ab97443d486b35920ebf880cd",
      "657bd3918a9b43f8a8c2739aaae1d60e",
      "5387fb075d344db384a0cd5f93d7b00a"
     ]
    },
    "id": "2CcIGaExk-qV",
    "outputId": "d03acb62-cc27-4f93-dca4-6e81e3d7f212"
   },
   "outputs": [],
   "source": [
    "model_name = 'dmis-lab/biobert-base-cased-v1.1'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QQRWY6KJlAOY"
   },
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['text'], padding='max_length', truncation=True, max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 168,
     "referenced_widgets": [
      "ac60b2e7cdcc47c7b08c74b08f1d4f3b",
      "c0526cb7a2e14219a07bc059af40f36f",
      "ca45f0628e24478da82f4e44f584497b",
      "163aebc7e729429d805bae9ba5fc8dff",
      "fdac65a59de241689bc547630bf10297",
      "82ce07f873fe4d71ab08befe641fe3b3",
      "185d4c5aac00405ca2cad0ffd2eccd7d",
      "e839e0a646af4b0081f26c7a0f9759b4",
      "c1780e18e45d459d8f0f14126146d059",
      "34ffd2d31669409eb048db8ed82c283f",
      "6a8c3ccd35ec40b6992f60ce952f2516",
      "8b8839b0b29242ebb060771775a5dc2a",
      "a8f05e22283d4dfd8d1e77f98aecd701",
      "a8c632f6aedc475ca21fd538b019a46d",
      "cd43be805e29440e8120ca4a7612a1a2",
      "d7b3a1711c154fcfb9705ff2caaab575",
      "55e0a8c3bbda49d38b87027b0919d4b6",
      "824762e054b04242b59856ce92a80836",
      "86c3486c9fce4e8dbb490da7e5930fc6",
      "d5becc3f08cf4efeb66e2c701ac823b7",
      "0ebea6024873431197ae323e222dbb22",
      "024661396ab54775a8a355ec674089c9",
      "f9b8dd16e8e14804b49850e02aec6398",
      "513db5bd7da64bf5ab85b1e74d9a03fc",
      "d3ba516c795b4bfcaa800134acce280c",
      "ac092fae71164514b91d4fdf6094f26d",
      "8d17006b0b66419b8ef06b1c512e0169",
      "4ce3a93de68b4b5d86a67869dc7e185c",
      "b8a4f1eb2653490bad850aba31a35771",
      "c58ed347fc95453e8cd5e49497c450d3",
      "e18d938c162a41aeb85582f390c7100b",
      "33d97c04f1004e269ae05ceed2648b2f",
      "517a3775557e4ab7bd2a2e724fda27ff"
     ]
    },
    "id": "huElrI0plCz6",
    "outputId": "9193f462-e3d4-4c6b-d33a-7d828d813ef6"
   },
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "val_dataset = val_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "num_labels = len(le.classes_)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6HWyAUsvlGCx"
   },
   "outputs": [],
   "source": [
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train_enc), y=y_train_enc)\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float).to('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IEFbbByzlKXc"
   },
   "outputs": [],
   "source": [
    "class WeightedTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
    "        labels = inputs.get('labels')\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get('logits')\n",
    "        loss_fct = torch.nn.CrossEntropyLoss(weight=self.class_weights)\n",
    "        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "b7ca8ea3453c4801ac324c18ace9e1f9",
      "6127b60683584726932a6db0e4ea27dc",
      "da2d9e97f7ca4bd3b4408682005b7818",
      "bd516cefa9d449999ef3cc2984f81fa4",
      "ec4db388692545a5b67b99e55ff519a1",
      "940d5bc62cab408dbe411323b7cc84c2",
      "28d3e75a49d540a5ac27f44d00f6a6b9",
      "1b68bf09cfc749f7af56f8897d2a2d5a",
      "e20c1ffccd6c46deaf8bdf2beca4b745",
      "78e4b62ece134d109dd189aabeb2f722",
      "3cb3420525814cf4a42cde41c3ac0aba"
     ]
    },
    "id": "JWw_vdjRlMrH",
    "outputId": "244ed1f1-f3cf-49c5-b8f5-c2ead113d093"
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./biobert_results',\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    learning_rate=2e-5,\n",
    "    logging_dir='./logs',\n",
    "    eval_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='f1',\n",
    "    greater_is_better=True,\n",
    "    fp16=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uEom8lOSlOuZ"
   },
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    f1_macro = f1_score(labels, preds, average='macro')\n",
    "    return {'accuracy': acc, 'f1': f1_macro}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "usBlEvFllPhA"
   },
   "outputs": [],
   "source": [
    "trainer = WeightedTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "trainer.class_weights = class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 582
    },
    "id": "J6yyn-6alQfc",
    "outputId": "7079b886-b5fd-4f86-cfec-6ff6b52fd4dd"
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "3mU9jPZDlSEy",
    "outputId": "01d303cd-53a2-43d1-aeda-bafa8bdedc8c"
   },
   "outputs": [],
   "source": [
    "results = trainer.evaluate()\n",
    "print(\"BioBERT Fine-Tuned Results:\", results)\n",
    "predictions = trainer.predict(val_dataset)\n",
    "y_pred_enc = predictions.predictions.argmax(-1)\n",
    "y_pred = le.inverse_transform(y_pred_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yZO4qxxYlYf3",
    "outputId": "e89b3054-11fa-4436-89b5-f0ff16c144cd"
   },
   "outputs": [],
   "source": [
    "acc_biobert = accuracy_score(y_val_enc, y_pred_enc)\n",
    "f1_biobert = f1_score(y_val_enc, y_pred_enc, average='macro')\n",
    "print(f\"BioBERT Accuracy: {acc_biobert:.4f}, Macro F1: {f1_biobert:.4f}\")\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 853
    },
    "id": "FRS0hmW1labi",
    "outputId": "91cff330-cd1e-40fc-b329-3e5067ea3442"
   },
   "outputs": [],
   "source": [
    "cm_biobert = confusion_matrix(y_val_enc, y_pred_enc)\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(cm_biobert, annot=False, cmap='Blues')\n",
    "plt.title('BioBERT Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7W6k5y7llbnf",
    "outputId": "f2c558e0-8c59-4cb8-c1af-50282622415f"
   },
   "outputs": [],
   "source": [
    "errors = pd.DataFrame({'Text': X_val[y_val != y_pred].values[:5], 'True': y_val[y_val != y_pred].values[:5], 'Pred': y_pred[y_val != y_pred][:5]})\n",
    "print(\"Sample Errors:\\n\", errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "960SDVA1sCDR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sk5qxqsf8dSk"
   },
   "source": [
    "**INCORPORATION OF LANGUAGE MODEL**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6_1ELuKYPiXc"
   },
   "source": [
    "EXTERNAL INCORPORATION OF LM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H-biyQif_dxH"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape, \"y_train shape:\", y_train.shape)\n",
    "print(\"X_val shape:\", X_val.shape, \"y_val shape:\", y_val.shape)\n",
    "\n",
    "api_token = \"\"\n",
    "api_url = \"https://api-inference.huggingface.co/models/facebook/bart-large-mnli\"\n",
    "headers = {\"Authorization\": f\"Bearer {api_token}\"}\n",
    "\n",
    "candidate_labels = list(le.classes_)[:10]\n",
    "print(f\"Number of candidate labels: {len(candidate_labels)}\")\n",
    "\n",
    "def query_external_lm(text, candidate_labels, retries=3, delay=5, timeout=60):\n",
    "    payload = {\n",
    "        \"inputs\": text,\n",
    "        \"parameters\": {\"candidate_labels\": candidate_labels},\n",
    "        \"options\": {\"wait_for_model\": True}\n",
    "    }\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            response = requests.post(api_url, headers=headers, json=payload, timeout=timeout)\n",
    "            if response.status_code == 200:\n",
    "                result = response.json()\n",
    "                if isinstance(result, dict) and 'scores' in result:\n",
    "                    score_dict = dict(zip(result.get('labels', candidate_labels), result['scores']))\n",
    "                    ordered_scores = [score_dict.get(label, 0.0) for label in candidate_labels]\n",
    "                    return ordered_scores\n",
    "                else:\n",
    "                    print(f\"Unexpected response format: {result}\")\n",
    "                    return [0.0] * len(candidate_labels)\n",
    "            else:\n",
    "                print(f\"API Error: {response.status_code} - {response.text}\")\n",
    "                if attempt < retries - 1:\n",
    "                    time.sleep(delay)\n",
    "                    continue\n",
    "                return [0.0] * len(candidate_labels)\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Request failed: {e}\")\n",
    "            if attempt < retries - 1:\n",
    "                time.sleep(delay)\n",
    "                continue\n",
    "            return [0.0] * len(candidate_labels)\n",
    "    return [0.0] * len(candidate_labels)\n",
    "\n",
    "def get_external_scores(texts, batch_size=5, max_samples=None):\n",
    "    scores_list = []\n",
    "    texts_to_process = texts[:max_samples] if max_samples else texts\n",
    "    print(f\"Processing {len(texts_to_process)} texts...\")\n",
    "\n",
    "    for i in tqdm(range(0, len(texts_to_process), batch_size), desc=\"Querying API\"):\n",
    "        batch_texts = texts_to_process[i:i+batch_size]\n",
    "        batch_scores = [query_external_lm(text, candidate_labels) for text in batch_texts]\n",
    "        scores_list.extend(batch_scores)\n",
    "        time.sleep(2)\n",
    "    return np.array(scores_list)\n",
    "\n",
    "max_samples = 100\n",
    "logger.info(\"Extracting external scores for X_val subset...\")\n",
    "external_scores = get_external_scores(X_val, batch_size=5, max_samples=max_samples)\n",
    "logger.info(f\"External scores shape: {external_scores.shape}\")\n",
    "\n",
    "if external_scores.size > 0:\n",
    "    clf_external = LogisticRegression(max_iter=1000, class_weight='balanced', multi_class='multinomial', solver='lbfgs')\n",
    "    clf_external.fit(external_scores, y_val_enc[:len(external_scores)])\n",
    "    y_pred_external_clf = clf_external.predict(external_scores)\n",
    "    acc_external_clf = accuracy_score(y_val_enc[:len(external_scores)], y_pred_external_clf)\n",
    "    f1_external_clf = f1_score(y_val_enc[:len(external_scores)], y_pred_external_clf, average='macro')\n",
    "    print(f\"External LM Scores as Features - Accuracy: {acc_external_clf:.4f}, Macro F1: {f1_external_clf:.4f}\")\n",
    "    print(\"External LM Scores Classification Report:\\n\",\n",
    "          classification_report(y_val[:len(external_scores)], le.inverse_transform(y_pred_external_clf), zero_division=0))\n",
    "else:\n",
    "    print(\"No external scores obtained, proceeding with internal model only.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ENKWMaIFPvwM"
   },
   "source": [
    "INTERNAL INCORPORATION OF LM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q-q3xEsTPduU"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1V1SArseTAkD",
    "outputId": "b5626b5a-8032-4be1-fdf9-c73f7560ac54"
   },
   "outputs": [],
   "source": [
    "df['features_raw'] = df['transcription'].fillna('') + ' ' + df['keywords'].fillna('')\n",
    "X_raw = df['features_raw']\n",
    "X_train_raw, X_val_raw, y_train, y_val = train_test_split(X_raw, df['medical_specialty'],\n",
    "                                                          test_size=0.2, random_state=42, stratify=df['medical_specialty'])\n",
    "le = LabelEncoder()\n",
    "y_train_enc = le.fit_transform(y_train)\n",
    "y_val_enc = le.transform(y_val)\n",
    "\n",
    "print(\"X_train_raw shape:\", X_train_raw.shape, \"y_train shape:\", y_train.shape)\n",
    "print(\"X_val_raw shape:\", X_val_raw.shape, \"y_val shape:\", y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "19T4lURLPbgm",
    "outputId": "f76466ca-34d1-4a16-9118-2e0804004f33"
   },
   "outputs": [],
   "source": [
    "print(\"X_train shape:\", X_train.shape, \"y_train shape:\", y_train.shape)\n",
    "print(\"X_val shape:\", X_val.shape, \"y_val shape:\", y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rDkzLaqgTuvQ"
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "v7_8F9ctS5lZ",
    "outputId": "a9e44d9d-f820-4b16-ea1c-e5215a337f7d"
   },
   "outputs": [],
   "source": [
    "model_name = 'dmis-lab/biobert-base-cased-v1.1'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "def extract_embeddings(texts, batch_size=16, pooling='mean'):\n",
    "    embeddings = []\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model.to(device)\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch_texts = texts[i:i+batch_size]\n",
    "        inputs = tokenizer(batch_texts.tolist(), padding=True, truncation=True, max_length=512, return_tensors='pt')\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        if pooling == 'mean':\n",
    "            attention_mask = inputs['attention_mask'].unsqueeze(-1)\n",
    "            masked_embeddings = outputs.last_hidden_state * attention_mask\n",
    "            batch_embeddings = masked_embeddings.sum(dim=1) / attention_mask.sum(dim=1)\n",
    "        else:\n",
    "            batch_embeddings = outputs.last_hidden_state[:, 0, :]\n",
    "        embeddings.append(batch_embeddings.cpu().numpy())\n",
    "    return np.vstack(embeddings)\n",
    "\n",
    "X_train_emb = extract_embeddings(X_train_raw, batch_size=16, pooling='mean')\n",
    "X_val_emb = extract_embeddings(X_val_raw, batch_size=16, pooling='mean')\n",
    "\n",
    "smote = SMOTE(random_state=42, k_neighbors=3)\n",
    "X_train_emb_resampled, y_train_enc_resampled = smote.fit_resample(X_train_emb, y_train_enc)\n",
    "\n",
    "clf_internal = XGBClassifier(n_estimators=200, max_depth=5, learning_rate=0.1,\n",
    "                            objective='multi:softmax', eval_metric='mlogloss', random_state=42)\n",
    "clf_internal.fit(X_train_emb_resampled, y_train_enc_resampled)\n",
    "\n",
    "y_pred_internal = clf_internal.predict(X_val_emb)\n",
    "acc_internal = accuracy_score(y_val_enc, y_pred_internal)\n",
    "f1_internal = f1_score(y_val_enc, y_pred_internal, average='macro')\n",
    "print(f\"Internal LM (BioBERT Embeddings + XGBoost) - Accuracy: {acc_internal:.4f}, Macro F1: {f1_internal:.4f}\")\n",
    "print(\"Internal LM Classification Report:\\n\",\n",
    "      classification_report(y_val, le.inverse_transform(y_pred_internal), zero_division=0))\n",
    "\n",
    "cm_internal = confusion_matrix(y_val_enc, y_pred_internal)\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(cm_internal, annot=False, cmap='Blues')\n",
    "plt.title('Internal LM Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()\n",
    "\n",
    "errors_internal = pd.DataFrame({\n",
    "    'Text': X_val_raw[y_val != le.inverse_transform(y_pred_internal)].values[:5],\n",
    "    'True': y_val[y_val != le.inverse_transform(y_pred_internal)].values[:5],\n",
    "    'Pred': le.inverse_transform(y_pred_internal)[y_val != le.inverse_transform(y_pred_internal)][:5]\n",
    "})\n",
    "print(\"Sample Errors (Internal LM):\\n\", errors_internal)\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "X_train_emb_2d = tsne.fit_transform(X_train_emb[:500])\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.scatterplot(x=X_train_emb_2d[:, 0], y=X_train_emb_2d[:, 1], hue=le.inverse_transform(y_train_enc[:500]),\n",
    "                palette='tab20', legend='full')\n",
    "plt.title('t-SNE Visualization of BioBERT Embeddings (Train Data)')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VHn_-9zjPma5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rQRx4cEdNfen"
   },
   "source": [
    "**EDA ON TRAIN TEST RESULTS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rmRYw52aM42h",
    "outputId": "1d349298-f8c2-45f9-9655-084ca548469b"
   },
   "outputs": [],
   "source": [
    "data = {\n",
    "    'Model': ['Baseline', 'Fine-Tuned BioBERT', 'Internal (XGBoost)'],\n",
    "    'Train_Accuracy': [0.45,0.69,  0.52],\n",
    "    'Val_Accuracy': [ 0.41,0.65, 0.52],\n",
    "    'Train_Macro_F1': [0.43,0.65,  0.56],\n",
    "}\n",
    "results_df = pd.DataFrame(data)\n",
    "\n",
    "train_lengths = X_train.apply(lambda x: len(x.split()))\n",
    "train_class_dist = y_train.value_counts(normalize=True)\n",
    "\n",
    "print(\"Results DataFrame:\\n\", results_df)\n",
    "print(\"\\nTrain Data Lengths Summary:\\n\", train_lengths.describe())\n",
    "print(\"\\nTrain Class Distribution (Top 5):\\n\", train_class_dist.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 671
    },
    "id": "9X97UZdGNucd",
    "outputId": "558532ca-1b25-4d47-db88-79acf0dae84b"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Model', y='Val_Accuracy', data=results_df, palette='viridis')\n",
    "plt.title('Validation Accuracy Across Models')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Model')\n",
    "plt.ylim(0, 1)\n",
    "for i, v in enumerate(results_df['Val_Accuracy']):\n",
    "    plt.text(i, v + 0.02, f'{v:.2f}', ha='center')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "6FtTQjhTNyTa",
    "outputId": "9a2a440a-4ae6-46b8-9202-117deaecab1b"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(data=results_df[['Train_Accuracy', 'Val_Accuracy']].T, markers=True)\n",
    "plt.title('Train vs. Validation Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Model Index (0=BioBERT, 1=Baseline, 2=Internal)')\n",
    "plt.legend(['Train', 'Validation'])\n",
    "plt.xticks([0, 1, 2], results_df['Model'])\n",
    "plt.ylim(0, 1)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
